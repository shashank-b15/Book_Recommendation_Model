{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\manik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\manik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing all the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1F6404F1VG29J</td>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>Avidreader</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I enjoy vintage books and movies so I enjoyed ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Nice vintage story</td>\n",
       "      <td>1399248000</td>\n",
       "      <td>05 5, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AN0N05A9LIJEQ</td>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>critters</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>This book is a reissue of an old one; the auth...</td>\n",
       "      <td>4</td>\n",
       "      <td>Different...</td>\n",
       "      <td>1388966400</td>\n",
       "      <td>01 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A795DMNCJILA6</td>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>dot</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>This was a fairly interesting read.  It had ol...</td>\n",
       "      <td>4</td>\n",
       "      <td>Oldie</td>\n",
       "      <td>1396569600</td>\n",
       "      <td>04 4, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1FV0SX13TWVXQ</td>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>Elaine H. Turley \"Montana Songbird\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>I'd never read any of the Amy Brewster mysteri...</td>\n",
       "      <td>5</td>\n",
       "      <td>I really liked it.</td>\n",
       "      <td>1392768000</td>\n",
       "      <td>02 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3SPTOKDG7WBLN</td>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>Father Dowling Fan</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>If you like period pieces - clothing, lingo, y...</td>\n",
       "      <td>4</td>\n",
       "      <td>Period Mystery</td>\n",
       "      <td>1395187200</td>\n",
       "      <td>03 19, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                         reviewerName helpful  \\\n",
       "0  A1F6404F1VG29J  B000F83SZQ                           Avidreader  [0, 0]   \n",
       "1   AN0N05A9LIJEQ  B000F83SZQ                             critters  [2, 2]   \n",
       "2   A795DMNCJILA6  B000F83SZQ                                  dot  [2, 2]   \n",
       "3  A1FV0SX13TWVXQ  B000F83SZQ  Elaine H. Turley \"Montana Songbird\"  [1, 1]   \n",
       "4  A3SPTOKDG7WBLN  B000F83SZQ                   Father Dowling Fan  [0, 1]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  I enjoy vintage books and movies so I enjoyed ...        5   \n",
       "1  This book is a reissue of an old one; the auth...        4   \n",
       "2  This was a fairly interesting read.  It had ol...        4   \n",
       "3  I'd never read any of the Amy Brewster mysteri...        5   \n",
       "4  If you like period pieces - clothing, lingo, y...        4   \n",
       "\n",
       "              summary  unixReviewTime   reviewTime  \n",
       "0  Nice vintage story      1399248000   05 5, 2014  \n",
       "1        Different...      1388966400   01 6, 2014  \n",
       "2               Oldie      1396569600   04 4, 2014  \n",
       "3  I really liked it.      1392768000  02 19, 2014  \n",
       "4      Period Mystery      1395187200  03 19, 2014  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.read_json(r\"C:\\Users\\manik\\Downloads\\kindle_reviews\\kindle_reviews.json\", lines=True)\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Dictionary**<br>\n",
    "asin - ID of the product <br>\n",
    "helpful - helpfulness rating of the review <br>\n",
    "overall - rating of the product <br>\n",
    "reviewText - text of the review (heading) <br>\n",
    "reviewTime - time of the review (raw) <br>\n",
    "reviewerID - ID of the reviewer <br>\n",
    "reviewerName - name of the reviewer <br>\n",
    "summary - summary of the review<br>\n",
    "unixReviewTime - unix timestamp <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61934\n"
     ]
    }
   ],
   "source": [
    "unique_items_count = reviews_df['asin'].nunique()\n",
    "print(unique_items_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "982619"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_counts = reviews_df[\"asin\"].value_counts()\n",
    "products_filtered = product_counts[product_counts>=50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df_filtered = reviews_df.query(\"asin in @products_filtered.index.tolist()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>A19V8I1LEHA1YW</td>\n",
       "      <td>B000JMLBHU</td>\n",
       "      <td>Alexander Hollins \"Author, Reader, Editor, Tired\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>A manual on desert island survival in its own ...</td>\n",
       "      <td>4</td>\n",
       "      <td>A classic for a reason</td>\n",
       "      <td>1404000000</td>\n",
       "      <td>06 29, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>A3J5D9XN0QT9AG</td>\n",
       "      <td>B000JMLBHU</td>\n",
       "      <td>Allrie</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I remember going to the movie theatre when abo...</td>\n",
       "      <td>5</td>\n",
       "      <td>Trouble</td>\n",
       "      <td>1367366400</td>\n",
       "      <td>05 1, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>A33EX8MZYBV0YI</td>\n",
       "      <td>B000JMLBHU</td>\n",
       "      <td>alone with books</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>this was an Ok book, but slow at times, I actu...</td>\n",
       "      <td>3</td>\n",
       "      <td>the Mysterrous Island</td>\n",
       "      <td>1374537600</td>\n",
       "      <td>07 23, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>A3HK1FZVP03IIC</td>\n",
       "      <td>B000JMLBHU</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Classic. What else needs to be said. An advent...</td>\n",
       "      <td>4</td>\n",
       "      <td>Classic</td>\n",
       "      <td>1358208000</td>\n",
       "      <td>01 15, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>A27EEX3H2CB70G</td>\n",
       "      <td>B000JMLBHU</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I read the who thing on my phone.  Enjoyed it ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Good Story</td>\n",
       "      <td>1365638400</td>\n",
       "      <td>04 11, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982567</th>\n",
       "      <td>A20MYFNLY6TGNL</td>\n",
       "      <td>B00LZKMXBI</td>\n",
       "      <td>The Book Fairy \"The Book Fairy\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Amazing! I was crying from page 1 And sweating...</td>\n",
       "      <td>5</td>\n",
       "      <td>Tears galore!!!!</td>\n",
       "      <td>1406073600</td>\n",
       "      <td>07 23, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982568</th>\n",
       "      <td>A19DWIC1T7127Y</td>\n",
       "      <td>B00LZKMXBI</td>\n",
       "      <td>T</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>I received an advanced reader's copy of this b...</td>\n",
       "      <td>4</td>\n",
       "      <td>Moving On</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>07 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982569</th>\n",
       "      <td>A28E8S7CY2LJ5W</td>\n",
       "      <td>B00LZKMXBI</td>\n",
       "      <td>Tlh</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Grab tissues, the first few pages had me cryin...</td>\n",
       "      <td>5</td>\n",
       "      <td>Grab your tissues and enjoy a great story !!!!!</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>07 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982570</th>\n",
       "      <td>A2GCYN1TPTKX72</td>\n",
       "      <td>B00LZKMXBI</td>\n",
       "      <td>Tricia</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>ARC review..... Let me just start by saying I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Awesome!!!!!</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>07 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982571</th>\n",
       "      <td>A1098Z3D7ENJ2F</td>\n",
       "      <td>B00LZKMXBI</td>\n",
       "      <td>veronica mostel</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>What a great story. I really enjoyed it. Sad b...</td>\n",
       "      <td>5</td>\n",
       "      <td>Wow</td>\n",
       "      <td>1405987200</td>\n",
       "      <td>07 22, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255419 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID        asin  \\\n",
       "189     A19V8I1LEHA1YW  B000JMLBHU   \n",
       "190     A3J5D9XN0QT9AG  B000JMLBHU   \n",
       "191     A33EX8MZYBV0YI  B000JMLBHU   \n",
       "192     A3HK1FZVP03IIC  B000JMLBHU   \n",
       "193     A27EEX3H2CB70G  B000JMLBHU   \n",
       "...                ...         ...   \n",
       "982567  A20MYFNLY6TGNL  B00LZKMXBI   \n",
       "982568  A19DWIC1T7127Y  B00LZKMXBI   \n",
       "982569  A28E8S7CY2LJ5W  B00LZKMXBI   \n",
       "982570  A2GCYN1TPTKX72  B00LZKMXBI   \n",
       "982571  A1098Z3D7ENJ2F  B00LZKMXBI   \n",
       "\n",
       "                                             reviewerName helpful  \\\n",
       "189     Alexander Hollins \"Author, Reader, Editor, Tired\"  [0, 0]   \n",
       "190                                                Allrie  [0, 0]   \n",
       "191                                      alone with books  [0, 0]   \n",
       "192                                       Amazon Customer  [0, 0]   \n",
       "193                                       Amazon Customer  [0, 0]   \n",
       "...                                                   ...     ...   \n",
       "982567                    The Book Fairy \"The Book Fairy\"  [0, 0]   \n",
       "982568                                                  T  [3, 3]   \n",
       "982569                                                Tlh  [1, 1]   \n",
       "982570                                             Tricia  [4, 5]   \n",
       "982571                                    veronica mostel  [0, 1]   \n",
       "\n",
       "                                               reviewText  overall  \\\n",
       "189     A manual on desert island survival in its own ...        4   \n",
       "190     I remember going to the movie theatre when abo...        5   \n",
       "191     this was an Ok book, but slow at times, I actu...        3   \n",
       "192     Classic. What else needs to be said. An advent...        4   \n",
       "193     I read the who thing on my phone.  Enjoyed it ...        4   \n",
       "...                                                   ...      ...   \n",
       "982567  Amazing! I was crying from page 1 And sweating...        5   \n",
       "982568  I received an advanced reader's copy of this b...        4   \n",
       "982569  Grab tissues, the first few pages had me cryin...        5   \n",
       "982570  ARC review..... Let me just start by saying I ...        5   \n",
       "982571  What a great story. I really enjoyed it. Sad b...        5   \n",
       "\n",
       "                                                summary  unixReviewTime  \\\n",
       "189                              A classic for a reason      1404000000   \n",
       "190                                             Trouble      1367366400   \n",
       "191                               the Mysterrous Island      1374537600   \n",
       "192                                             Classic      1358208000   \n",
       "193                                          Good Story      1365638400   \n",
       "...                                                 ...             ...   \n",
       "982567                                 Tears galore!!!!      1406073600   \n",
       "982568                                        Moving On      1405900800   \n",
       "982569  Grab your tissues and enjoy a great story !!!!!      1405900800   \n",
       "982570                                     Awesome!!!!!      1405900800   \n",
       "982571                                              Wow      1405987200   \n",
       "\n",
       "         reviewTime  \n",
       "189     06 29, 2014  \n",
       "190      05 1, 2013  \n",
       "191     07 23, 2013  \n",
       "192     01 15, 2013  \n",
       "193     04 11, 2013  \n",
       "...             ...  \n",
       "982567  07 23, 2014  \n",
       "982568  07 21, 2014  \n",
       "982569  07 21, 2014  \n",
       "982570  07 21, 2014  \n",
       "982571  07 22, 2014  \n",
       "\n",
       "[255419 rows x 9 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the filtered dataframe we are keeping only products that are reviews atleast 50 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective was to build a recommendation system based on the reviews. Now we want to process our dataset, our thoughts was to sample the data from the helpful column which says out of the people who saw the review how many found it helpful, this is our first thought. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df[\"helpful\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now I want to check for the ones which are more helpful based on the percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manik\\AppData\\Local\\Temp\\ipykernel_31704\\3949530801.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reviews_df_filtered[\"help_percentage\"] = reviews_df_filtered[\"helpful\"].apply(lambda x : x[0]/x[1] if x[1]!=0 else 1)\n"
     ]
    }
   ],
   "source": [
    "reviews_df_filtered[\"help_percentage\"] = reviews_df_filtered[\"helpful\"].apply(lambda x : x[0]/x[1] if x[1]!=0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df_filtered = reviews_df_filtered.query(\"help_percentage>=0.8\").reset_index(drop =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(222231, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now again we filtered those reviews which are really helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df_filtered.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID            0\n",
       "asin                  0\n",
       "reviewerName       2016\n",
       "helpful               0\n",
       "reviewText            0\n",
       "overall               0\n",
       "summary               0\n",
       "unixReviewTime        0\n",
       "reviewTime            0\n",
       "help_percentage       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df_filtered.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unicode Normalization \n",
    "import unicodedata\n",
    "normalized_text = reviews_df_filtered['reviewText'].apply(lambda x: unicodedata.normalize('NFC', x))\n",
    "reviews_df_filtered['reviewText'] = normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>help_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A19V8I1LEHA1YW</td>\n",
       "      <td>B000JMLBHU</td>\n",
       "      <td>Alexander Hollins \"Author, Reader, Editor, Tired\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>A manual on desert island survival in its own ...</td>\n",
       "      <td>4</td>\n",
       "      <td>A classic for a reason</td>\n",
       "      <td>1404000000</td>\n",
       "      <td>06 29, 2014</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3J5D9XN0QT9AG</td>\n",
       "      <td>B000JMLBHU</td>\n",
       "      <td>Allrie</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I remember going to the movie theatre when abo...</td>\n",
       "      <td>5</td>\n",
       "      <td>Trouble</td>\n",
       "      <td>1367366400</td>\n",
       "      <td>05 1, 2013</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A33EX8MZYBV0YI</td>\n",
       "      <td>B000JMLBHU</td>\n",
       "      <td>alone with books</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>this was an Ok book, but slow at times, I actu...</td>\n",
       "      <td>3</td>\n",
       "      <td>the Mysterrous Island</td>\n",
       "      <td>1374537600</td>\n",
       "      <td>07 23, 2013</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3HK1FZVP03IIC</td>\n",
       "      <td>B000JMLBHU</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Classic. What else needs to be said. An advent...</td>\n",
       "      <td>4</td>\n",
       "      <td>Classic</td>\n",
       "      <td>1358208000</td>\n",
       "      <td>01 15, 2013</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A27EEX3H2CB70G</td>\n",
       "      <td>B000JMLBHU</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I read the who thing on my phone.  Enjoyed it ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Good Story</td>\n",
       "      <td>1365638400</td>\n",
       "      <td>04 11, 2013</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222226</th>\n",
       "      <td>A163XZU3HM4EHV</td>\n",
       "      <td>B00LZKMXBI</td>\n",
       "      <td>Stacy Hahn</td>\n",
       "      <td>[14, 17]</td>\n",
       "      <td>This book was absolutely perfect! Second Chanc...</td>\n",
       "      <td>5</td>\n",
       "      <td>I Loved it!!!</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>07 21, 2014</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222227</th>\n",
       "      <td>A20MYFNLY6TGNL</td>\n",
       "      <td>B00LZKMXBI</td>\n",
       "      <td>The Book Fairy \"The Book Fairy\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Amazing! I was crying from page 1 And sweating...</td>\n",
       "      <td>5</td>\n",
       "      <td>Tears galore!!!!</td>\n",
       "      <td>1406073600</td>\n",
       "      <td>07 23, 2014</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222228</th>\n",
       "      <td>A19DWIC1T7127Y</td>\n",
       "      <td>B00LZKMXBI</td>\n",
       "      <td>T</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>I received an advanced reader's copy of this b...</td>\n",
       "      <td>4</td>\n",
       "      <td>Moving On</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>07 21, 2014</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222229</th>\n",
       "      <td>A28E8S7CY2LJ5W</td>\n",
       "      <td>B00LZKMXBI</td>\n",
       "      <td>Tlh</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Grab tissues, the first few pages had me cryin...</td>\n",
       "      <td>5</td>\n",
       "      <td>Grab your tissues and enjoy a great story !!!!!</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>07 21, 2014</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222230</th>\n",
       "      <td>A2GCYN1TPTKX72</td>\n",
       "      <td>B00LZKMXBI</td>\n",
       "      <td>Tricia</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>ARC review..... Let me just start by saying I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Awesome!!!!!</td>\n",
       "      <td>1405900800</td>\n",
       "      <td>07 21, 2014</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222231 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID        asin  \\\n",
       "0       A19V8I1LEHA1YW  B000JMLBHU   \n",
       "1       A3J5D9XN0QT9AG  B000JMLBHU   \n",
       "2       A33EX8MZYBV0YI  B000JMLBHU   \n",
       "3       A3HK1FZVP03IIC  B000JMLBHU   \n",
       "4       A27EEX3H2CB70G  B000JMLBHU   \n",
       "...                ...         ...   \n",
       "222226  A163XZU3HM4EHV  B00LZKMXBI   \n",
       "222227  A20MYFNLY6TGNL  B00LZKMXBI   \n",
       "222228  A19DWIC1T7127Y  B00LZKMXBI   \n",
       "222229  A28E8S7CY2LJ5W  B00LZKMXBI   \n",
       "222230  A2GCYN1TPTKX72  B00LZKMXBI   \n",
       "\n",
       "                                             reviewerName   helpful  \\\n",
       "0       Alexander Hollins \"Author, Reader, Editor, Tired\"    [0, 0]   \n",
       "1                                                  Allrie    [0, 0]   \n",
       "2                                        alone with books    [0, 0]   \n",
       "3                                         Amazon Customer    [0, 0]   \n",
       "4                                         Amazon Customer    [0, 0]   \n",
       "...                                                   ...       ...   \n",
       "222226                                         Stacy Hahn  [14, 17]   \n",
       "222227                    The Book Fairy \"The Book Fairy\"    [0, 0]   \n",
       "222228                                                  T    [3, 3]   \n",
       "222229                                                Tlh    [1, 1]   \n",
       "222230                                             Tricia    [4, 5]   \n",
       "\n",
       "                                               reviewText  overall  \\\n",
       "0       A manual on desert island survival in its own ...        4   \n",
       "1       I remember going to the movie theatre when abo...        5   \n",
       "2       this was an Ok book, but slow at times, I actu...        3   \n",
       "3       Classic. What else needs to be said. An advent...        4   \n",
       "4       I read the who thing on my phone.  Enjoyed it ...        4   \n",
       "...                                                   ...      ...   \n",
       "222226  This book was absolutely perfect! Second Chanc...        5   \n",
       "222227  Amazing! I was crying from page 1 And sweating...        5   \n",
       "222228  I received an advanced reader's copy of this b...        4   \n",
       "222229  Grab tissues, the first few pages had me cryin...        5   \n",
       "222230  ARC review..... Let me just start by saying I ...        5   \n",
       "\n",
       "                                                summary  unixReviewTime  \\\n",
       "0                                A classic for a reason      1404000000   \n",
       "1                                               Trouble      1367366400   \n",
       "2                                 the Mysterrous Island      1374537600   \n",
       "3                                               Classic      1358208000   \n",
       "4                                            Good Story      1365638400   \n",
       "...                                                 ...             ...   \n",
       "222226                                    I Loved it!!!      1405900800   \n",
       "222227                                 Tears galore!!!!      1406073600   \n",
       "222228                                        Moving On      1405900800   \n",
       "222229  Grab your tissues and enjoy a great story !!!!!      1405900800   \n",
       "222230                                     Awesome!!!!!      1405900800   \n",
       "\n",
       "         reviewTime  help_percentage  \n",
       "0       06 29, 2014         1.000000  \n",
       "1        05 1, 2013         1.000000  \n",
       "2       07 23, 2013         1.000000  \n",
       "3       01 15, 2013         1.000000  \n",
       "4       04 11, 2013         1.000000  \n",
       "...             ...              ...  \n",
       "222226  07 21, 2014         0.823529  \n",
       "222227  07 23, 2014         1.000000  \n",
       "222228  07 21, 2014         1.000000  \n",
       "222229  07 21, 2014         1.000000  \n",
       "222230  07 21, 2014         0.800000  \n",
       "\n",
       "[222231 rows x 10 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted spaces,extra trailing and leading spaces,punctuations,full-stops,inverted commas,special characters\n",
    "import re\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text) \n",
    "    return cleaned_text.strip()\n",
    "reviews_df_filtered['reviewText'] = reviews_df_filtered['reviewText'].apply(lambda x: clean_text(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     filtered_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(filtered_tokens)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filtered_text\n\u001b[1;32m----> 8\u001b[0m reviews_df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mreviews_df_filtered\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreviewText\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_stopwords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:4758\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4632\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4633\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4635\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4762\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4763\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4764\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4765\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:1201\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:1281\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1281\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1286\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning a DataFrame from Series.apply when the supplied function \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturns a Series is deprecated and will be removed in a future \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1291\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1292\u001b[0m     )  \u001b[38;5;66;03m# GH52116\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\algorithms.py:1812\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1810\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1815\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1816\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2917\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[64], line 8\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      6\u001b[0m     filtered_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(filtered_tokens)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filtered_text\n\u001b[1;32m----> 8\u001b[0m reviews_df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m reviews_df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mremove_stopwords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[64], line 4\u001b[0m, in \u001b[0;36mremove_stopwords\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_stopwords\u001b[39m(text):\n\u001b[0;32m      3\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m word_tokenize(text)    \n\u001b[1;32m----> 4\u001b[0m     stop_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mstopwords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menglish\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      5\u001b[0m     filtered_tokens \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words]\n\u001b[0;32m      6\u001b[0m     filtered_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(filtered_tokens)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py:21\u001b[0m, in \u001b[0;36mWordListCorpusReader.words\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwords\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ignore_lines_startswith\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m     20\u001b[0m         line\n\u001b[1;32m---> 21\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m line_tokenize(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileids\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstartswith(ignore_lines_startswith)\n\u001b[0;32m     23\u001b[0m     ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\reader\\api.py:218\u001b[0m, in \u001b[0;36mCorpusReader.raw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m    216\u001b[0m contents \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fileids:\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    219\u001b[0m         contents\u001b[38;5;241m.\u001b[39mappend(fp\u001b[38;5;241m.\u001b[39mread())\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concat(contents)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\reader\\api.py:231\u001b[0m, in \u001b[0;36mCorpusReader.open\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03mReturn an open stream that can be used to read the given file.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03mIf the file's encoding is not None, then the stream will\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m:param file: The file identifier of the file to read.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    230\u001b[0m encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding(file)\n\u001b[1;32m--> 231\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_root\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\data.py:324\u001b[0m, in \u001b[0;36mFileSystemPathPointer.open\u001b[1;34m(self, encoding)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 324\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         stream \u001b[38;5;241m=\u001b[39m SeekableUnicodeStreamReader(stream, encoding)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Removing stopwords from the dataset\n",
    "def remove_stopwords(text):\n",
    "    tokens = word_tokenize(text)    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n",
    "reviews_df_filtered['reviewText'] = reviews_df_filtered['reviewText'].apply(lambda x: remove_stopwords(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted spaces,extra trailing and leading spaces,punctuations,full-stops,inverted commas,special characters\n",
    "import re\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text) \n",
    "    return cleaned_text.strip()\n",
    "reviews_df_filtered['reviewText'] = reviews_df_filtered['reviewText'].apply(lambda x: clean_text(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df_filtered[\"reviewText\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_product = reviews_df_filtered.query(\"asin=='B000JMLBHU'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load sentiment analysis pipeline\n",
    "classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_product[\"truncated_text\"] = filtered_product[\"reviewText\"].apply(lambda x: classifier.tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_product[\"truncated_text\"] = filtered_product[\"truncated_text\"].apply(lambda x: ' '.join(x[:400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_product[\"sentiment_output\"] = filtered_product[\"truncated_text\"].apply(lambda x: classifier(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label_score(sentiment_dict):\n",
    "    \n",
    "    if sentiment_dict and isinstance(sentiment_dict, list):\n",
    "        return sentiment_dict[0]['label'], sentiment_dict[0]['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_product[['label', 'score']] = filtered_product['sentiment_output'].apply(lambda x: pd.Series(extract_label_score(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_product.query(\"label=='POSITIVE'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_product.iloc[1,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I remember going to the movie theatre when about 56/7 yrs old. with my cousin 4 years older.  We enjoyed it so much that we staye through a second showing--and got into huge trouble!  I saw the book's availability and realized that I'd never actually read the book.  It did not disappoint.  At our upcoming family reunion, I'd like to share that movie experience with my grandkids--but am sending them the book to enjoy first.\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.query(\"asin=='B000JMLBHU'\").iloc[1,4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
